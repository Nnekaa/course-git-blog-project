{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUcI1QN/mJOIWDObe4zL+q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nnekaa/course-git-blog-project/blob/master/Dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeTPxY-_kwn-",
        "outputId": "759fecd7-13ac-459f-b53a-bb3012559cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter username: d.momodu\n",
            "Please enter your password: ··········\n",
            "API token obtained: b464ef0bc14b14f9e070d9b5831087a55caaa7c2\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1744 entries, 0 to 164\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   site_name             1744 non-null   object\n",
            " 1   name                  1744 non-null   object\n",
            " 2   meter_number          1744 non-null   object\n",
            " 3   tariff_name           1744 non-null   object\n",
            " 4   phone_number          1744 non-null   object\n",
            " 5   coords                1744 non-null   object\n",
            " 6   customer_id           1744 non-null   object\n",
            " 7   account_balance       1744 non-null   object\n",
            " 8   site_id               1744 non-null   object\n",
            " 9   is_running_plan       1744 non-null   object\n",
            " 10  last_energy           1744 non-null   object\n",
            " 11  last_energy_datetime  1744 non-null   object\n",
            "dtypes: object(12)\n",
            "memory usage: 177.1+ KB\n",
            "Data streamed to BigQuery successfully.\n"
          ]
        }
      ],
      "source": [
        "#CUSTOMER DETAILS\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import json_normalize\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery.job import WriteDisposition\n",
        "import getpass\n",
        "\n",
        "import copy\n",
        "\n",
        "maijaki_url_customers = \"https://ppl-maijaki.sparkmeter.cloud/api/v0/customers\"\n",
        "maijaki_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwFwckRwCAIAMBeeIcZQS5ryeQhiP2XkN0XuiZHtuBIKxTngRFBWOZke10_5PDAihMVdTWm7SmerJqL-wxpJi34ftN3Eyo.Y9gTZw.nBM0bHvBvN_rDOZng3PKDEi42Hk\"\n",
        "}\n",
        "\n",
        "mbiabet_url_customers = \"https://ppl-mbiabet.sparkmeter.cloud/api/v0/customers\"\n",
        "mbiabet_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwFwcERgDAIBMBeeMsMkSD04vgALvRfgrsvaXfXEeGclbz1AZej2aKX-MDKlC7CsokHmjvr1lOQ0QlYeKqbbfp-GIsUhA.ZMFC2Q.69qla4gYX1I4hnvvHJxJc4tMpqg\"\n",
        "}\n",
        "\n",
        "aninigi_url_customers = \"https://ppl-aninigi.sparkmeter.cloud/api/v0/customers\"\n",
        "aninigi_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwFwckNwDAIBMBeeAfJB6yhligPg03_JWTmpYZpsOosIcGS53BIgjNmpI3yakUPrdnvUV8muZpB4QOeuy50d1XQ9wPrShOR.ZMFEHg.wOFXMGrYZzJ7T6OQh_-GPkWSYAQ\"\n",
        "}\n",
        "\n",
        "lafiya_kpada_url_customers = \"https://ppl-lafiya-kpada.sparkmeter.cloud/api/v0/customers\"\n",
        "lafiya_kpada_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwNx8kRwCAIAMBeeMcZRC5ryeShCP2XYPa3LwwUXMy7hYo3PkPbPF5_mXEFdZkKDyQVUaQhEqbZlmFhsyKoeqknfBfEchNJ.ZMFMBQ.sCBMXVMm2xb4HTBQMyXVAXr3MBE\"\n",
        "}\n",
        "\n",
        "def get_obj(url, header):\n",
        "    response = requests.get(url, headers=header)\n",
        "    customer_obj = response.json()\n",
        "    return customer_obj\n",
        "\n",
        "aninigi_customers_default_obj = get_obj(aninigi_url_customers, aninigi_headers)\n",
        "lafiya_kpada_customers_default_obj = get_obj(lafiya_kpada_url_customers, lafiya_kpada_headers)\n",
        "maijaki_customers_default_obj = get_obj(maijaki_url_customers, maijaki_headers)\n",
        "mbiabet_customers_default_obj = get_obj(mbiabet_url_customers, mbiabet_headers)\n",
        "\n",
        "mbiabet_customers = copy.deepcopy(mbiabet_customers_default_obj)\n",
        "aninigi_customers = copy.deepcopy(aninigi_customers_default_obj)\n",
        "lafiya_kpada_customers = copy.deepcopy(lafiya_kpada_customers_default_obj)\n",
        "maijaki_customers = copy.deepcopy(maijaki_customers_default_obj)\n",
        "\n",
        "def func(obj):\n",
        "  meters_obj = obj['meters'][0]\n",
        "  for key,value in meters_obj.items():\n",
        "    obj[key]=value\n",
        "  del obj['meters']\n",
        "  ground = obj['ground']\n",
        "  obj['ground_id'] = ground['id']\n",
        "  obj['ground_name'] = ground['name']\n",
        "  del obj['ground']\n",
        "  return obj\n",
        "\n",
        "maijaki_customers_list = list(map(func, maijaki_customers[\"customers\"]))\n",
        "mbiabet_customers_list = list(map(func, mbiabet_customers[\"customers\"]))\n",
        "aninigi_customers_list = list(map(func, aninigi_customers[\"customers\"]))\n",
        "lafiya_kpada_customers_list = list(map(func, lafiya_kpada_customers[\"customers\"]))\n",
        "\n",
        "lafiya_kpada_df = pd.DataFrame.from_records(lafiya_kpada_customers_list)\n",
        "aninigi_df = pd.DataFrame.from_records(aninigi_customers_list)\n",
        "mbiabet_df = pd.DataFrame.from_records(mbiabet_customers_list)\n",
        "maijaki_df = pd.DataFrame.from_records(maijaki_customers_list)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "maijaki_df['ground_name'] = 'Maijaki'\n",
        "aninigi_df['ground_name'] = 'Aninigi'\n",
        "mbiabet_df['ground_name'] = 'Mbiabet'\n",
        "lafiya_kpada_df['ground_name'] = 'Lafiya-Kpada'\n",
        "\n",
        "frames = [aninigi_df, lafiya_kpada_df, maijaki_df, mbiabet_df]\n",
        "spark_customers = pd.concat(frames)\n",
        "spark_customers = spark_customers[(spark_customers['active'] == True)]\n",
        "spark_customers.rename(columns = {'credit_balance':'account_balance', 'id':'customer_id', 'current_tariff_name':'tariff_name',\n",
        "                                  'serial':'meter_number', 'ground_id':'site_id', 'ground_name':'site_name'}, inplace = True)\n",
        "spark_customers = spark_customers[ ['site_name','name', 'meter_number', 'tariff_name', 'phone_number', 'coords', 'customer_id',\n",
        "                                    'account_balance','site_id','is_running_plan', 'last_energy','last_energy_datetime']]\n",
        "\n",
        "spark_customers['meter_number'] = spark_customers['meter_number'].astype(str)\n",
        "spark_customers['site_id'] = spark_customers['site_id'].astype(str)\n",
        "spark_customers['account_balance'] = spark_customers['account_balance'].astype(str)\n",
        "spark_customers['last_energy'] = spark_customers['last_energy'].astype(str)\n",
        "\n",
        "\n",
        "# Constants\n",
        "BASE_URL = \"https://api.steama.co\"\n",
        "TOKEN_ENDPOINT = f\"{BASE_URL}/get-token/\"\n",
        "CUSTOMERS_ENDPOINT = f\"{BASE_URL}/customers/\"\n",
        "\n",
        "# Helper function to get API token\n",
        "def get_api_token(username, password):\n",
        "    payload = {\"username\": username, \"password\": password}\n",
        "    response = requests.post(TOKEN_ENDPOINT, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"token\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Error obtaining API token: {response.status_code} - {response.text}\")\n",
        "\n",
        "# Helper function to get all customer data\n",
        "def get_all_customer_data(api_token):\n",
        "    headers = {\"Authorization\": f\"Token {api_token}\"}\n",
        "    all_data = []\n",
        "    url = CUSTOMERS_ENDPOINT\n",
        "    while url:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            all_data.extend(data[\"results\"])\n",
        "            url = data[\"next\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Error: {response.status_code} - {response.text}\")\n",
        "    return all_data\n",
        "\n",
        "# Helper function to process customer data\n",
        "def process_customer_data(raw_data):\n",
        "    df = pd.json_normalize(raw_data)\n",
        "    df = df.drop(columns=[\"tags\"])\n",
        "    df = df.rename(columns={'utility_use_30_days.1': 'utility_use_30_days'})\n",
        "    return df\n",
        "# Helper function to load DataFrame into BigQuery\n",
        "\n",
        "def main():\n",
        "    # Get user credentials\n",
        "    username = input(\"Please enter username: \")\n",
        "    password = getpass.getpass(\"Please enter your password: \")\n",
        "\n",
        "    # Obtain API token\n",
        "    try:\n",
        "        api_token = get_api_token(username, password)\n",
        "        print(f\"API token obtained: {api_token}\")\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        exit(1)\n",
        "\n",
        "    # Fetch and process customer data\n",
        "    try:\n",
        "        raw_data = get_all_customer_data(api_token)\n",
        "        customers_df = process_customer_data(raw_data)\n",
        "        customers_df['name'] = customers_df['first_name'] + ' ' + customers_df['last_name']\n",
        "        customers_df['coords'] = customers_df['latitude'] + ',' + customers_df['longitude']\n",
        "        customers_df.rename(columns = {'id': 'customer_id', 'telephone': 'phone_number', 'service_based_tariff':'tariff_name',\n",
        "                                       'site': 'site_id'}, inplace = True)\n",
        "\n",
        "        customers_df['meter_number'] = \" \"\n",
        "        customers_df['is_running_plan'] = ' '\n",
        "        customers_df['last_energy'] = \" \"\n",
        "        customers_df['last_energy'] = \" \"\n",
        "        customers_df['last_energy_datetime'] = \" \"\n",
        "\n",
        "        customers_df = customers_df[['site_name','name', 'meter_number', 'tariff_name', 'phone_number', 'customer_id',\n",
        "                                    'account_balance','site_id']]\n",
        "        customers_df['meter_number'] = customers_df['meter_number'].astype(str)\n",
        "        customers_df['site_id'] = customers_df['site_id'].astype(str)\n",
        "\n",
        "        return customers_df\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    customers_df = main()\n",
        "\n",
        "customer_data_list = [spark_customers, customers_df]\n",
        "customer_data = pd.concat(customer_data_list)\n",
        "customer_data = customer_data.astype(str)\n",
        "customer_data.info()\n",
        "\n",
        "project_id = \"minigrid-db-395810\"\n",
        "dataset_id = \"Customers\"\n",
        "\n",
        "auth.authenticate_user()\n",
        "client =bigquery.Client(project=project_id)\n",
        "\n",
        "def func2(df):\n",
        "  schema = []\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype.name.lower() == \"int64\":\n",
        "      col_type = \"INTEGER\"\n",
        "    elif df[col].dtype.name.lower() == \"float64\":\n",
        "      col_type = \"FLOAT\"\n",
        "    elif df[col].dtype.name.lower() == \"bool\":\n",
        "      col_type = \"BOOLEAN\"\n",
        "    else:\n",
        "      col_type = \"STRING\"\n",
        "  schema.append(bigquery.SchemaField(col, col_type, mode=\"NULLABLE\"))\n",
        "  return schema\n",
        "\n",
        "customers_table_id = \"customers_data\"\n",
        "customers_table_ref = bigquery.TableReference.from_string(f\"{project_id}.{dataset_id}.{customers_table_id}\")\n",
        "customers_table = bigquery.Table(customers_table_ref, schema= func2(customer_data))\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE, create_disposition=\"CREATE_IF_NEEDED\")\n",
        "client.load_table_from_dataframe(customer_data, customers_table, job_config=job_config).result()\n",
        "\n",
        "print(\"Data streamed to BigQuery successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery.job import WriteDisposition\n",
        "import getpass\n",
        "\n",
        "\n",
        "aninigi_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwFwckNwDAIBMBeeAfJB6yhligPg03_JWTmpYZpsOosIcGS53BIgjNmpI3yakUPrdnvUV8muZpB4QOeuy50d1XQ9wPrShOR.ZMFEHg.wOFXMGrYZzJ7T6OQh_-GPkWSYAQ\"\n",
        "}\n",
        "\n",
        "maijaki_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwFwckRwCAIAMBeeIcZQS5ryeQhiP2XkN0XuiZHtuBIKxTngRFBWOZke10_5PDAihMVdTWm7SmerJqL-wxpJi34ftN3Eyo.Y9gTZw.nBM0bHvBvN_rDOZng3PKDEi42Hk\"\n",
        "}\n",
        "\n",
        "mbiabet_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwFwcERgDAIBMBeeMsMkSD04vgALvRfgrsvaXfXEeGclbz1AZej2aKX-MDKlC7CsokHmjvr1lOQ0QlYeKqbbfp-GIsUhA.ZMFC2Q.69qla4gYX1I4hnvvHJxJc4tMpqg\"\n",
        "}\n",
        "\n",
        "lafiya_kpada_headers = {\n",
        "     \"Content-Type\": \"application/json\",\n",
        "     \"Authentication-Token\": \".eJwNx8kRwCAIAMBeeMcZRC5ryeShCP2XYPa3LwwUXMy7hYo3PkPbPF5_mXEFdZkKDyQVUaQhEqbZlmFhsyKoeqknfBfEchNJ.ZMFMBQ.sCBMXVMm2xb4HTBQMyXVAXr3MBE\"\n",
        "}\n",
        "\n",
        "#Get table for sales accounts\n",
        "maijaki_sales_accounts_url = \"https://ppl-maijaki.sparkmeter.cloud/api/v0/sales-accounts\"\n",
        "aninigi_sales_accounts_url = \"https://ppl-aninigi.sparkmeter.cloud/api/v0/sales-accounts\"\n",
        "mbiabet_sales_accounts_url = \"https://ppl-mbiabet.sparkmeter.cloud/api/v0/sales-accounts\"\n",
        "lafiya_sales_accounts_url = \"https://ppl-lafiya-kpada.sparkmeter.cloud/api/v0/sales-accounts\"\n",
        "\n",
        "project_id = \"minigrid-db-395810\"\n",
        "dataset_id = \"Agents\"\n",
        "\n",
        "def sales_account_df(sales_accounts_url, header):\n",
        "    sales_response = requests.get(sales_accounts_url, headers=header)\n",
        "    sales_response_obj = sales_response.json()\n",
        "\n",
        "    sales_accounts_df = pd.DataFrame.from_records(sales_response_obj)\n",
        "    sales_accounts_df = pd.json_normalize(sales_accounts_df.pop(\"accounts\"))\n",
        "    return sales_accounts_df\n",
        "\n",
        "aninigi_agents_df = sales_account_df(aninigi_sales_accounts_url,aninigi_headers)\n",
        "aninigi_agents_df['site_name'] = 'Aninigi'\n",
        "maijaki_agents_df = sales_account_df(maijaki_sales_accounts_url,maijaki_headers)\n",
        "maijaki_agents_df['site_name'] = 'Maijaki'\n",
        "mbiabet_agents_df = sales_account_df(mbiabet_sales_accounts_url,mbiabet_headers)\n",
        "mbiabet_agents_df['site_name'] = 'Mbiabet'\n",
        "lafiya_agents_df = sales_account_df(lafiya_sales_accounts_url,lafiya_kpada_headers)\n",
        "lafiya_agents_df['site_name'] = 'Lafiya-Kpada'\n",
        "agents_frame = [aninigi_agents_df, maijaki_agents_df, mbiabet_agents_df, lafiya_agents_df]\n",
        "agents_df = pd.concat(agents_frame)\n",
        "agents_df.rename(columns = {'credit':'credit_balance'}, inplace = True)\n",
        "\n",
        "agents_df = agents_df[['id', 'name', 'site_name', 'credit_balance']]\n",
        "agents_df['credit_balance'] = agents_df['credit_balance'].astype(str)\n",
        "\n",
        "\n",
        "#STEAMACO AGENTS\n",
        "BASE_URL = \"https://api.steama.co\"\n",
        "TOKEN_ENDPOINT = f\"{BASE_URL}/get-token/\"\n",
        "AGENTS_ENDPOINT = f\"{BASE_URL}/agents/\"\n",
        "PROJECT_ID = \"minigrid-db\"\n",
        "TABLE_ID = \"minigrid-db.raw_zone.steamaco_agents\"\n",
        "\n",
        "# Helper function to get API token\n",
        "def get_api_token(username, password):\n",
        "    payload = {\"username\": username, \"password\": password}\n",
        "    response = requests.post(TOKEN_ENDPOINT, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"token\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Error obtaining API token: {response.status_code} - {response.text}\")\n",
        "\n",
        "# Helper function to get all customer data\n",
        "def get_all_agents_data(api_token):\n",
        "    headers = {\"Authorization\": f\"Token {api_token}\"}\n",
        "    all_data = []\n",
        "    url = AGENTS_ENDPOINT\n",
        "    while url:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            all_data.extend(data[\"results\"])\n",
        "            url = data[\"next\"]\n",
        "        else:\n",
        "            raise ValueError(f\"Error: {response.status_code} - {response.text}\")\n",
        "    return all_data\n",
        "\n",
        "# Helper function to process customer data\n",
        "def process_agents_data(raw_data):\n",
        "    df = pd.json_normalize(raw_data)\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    # Get user credentials\n",
        "    username = input(\"Please enter username: \")\n",
        "    password = getpass.getpass(\"Please enter your password: \")\n",
        "\n",
        "    # Obtain API token\n",
        "    try:\n",
        "        api_token = get_api_token(username, password)\n",
        "        print(f\"API token obtained: {api_token}\")\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        exit(1)\n",
        "\n",
        "    # Fetch and process customer data\n",
        "    try:\n",
        "        raw_data = get_all_agents_data(api_token)\n",
        "        steamaco_agents = process_agents_data(raw_data)\n",
        "        steamaco_agents['name'] = steamaco_agents['first_name'] + ' ' + steamaco_agents['last_name']\n",
        "        return steamaco_agents\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    agents1_df = main()\n",
        "\n",
        "agents1_df = agents1_df[['id', 'name', 'site_name', 'credit_balance']]\n",
        "\n",
        "all_agents_frame = [agents_df, agents1_df]\n",
        "agents = pd.concat(all_agents_frame)\n",
        "agents = agents.astype(str)\n",
        "\n",
        "dataset_id = \"Agents\"\n",
        "\n",
        "def load_agents_dataframe_to_bigquery(df, project_id, dataset_id,table_id):\n",
        "    client = bigquery.Client(project=project_id)\n",
        "    schema = []\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype.name.lower() == \"int64\":\n",
        "            col_type = \"INTEGER\"\n",
        "        elif df[col].dtype.name.lower() == \"float64\":\n",
        "            col_type = \"FLOAT\"\n",
        "        elif df[col].dtype.name.lower() == \"bool\":\n",
        "            col_type = \"BOOLEAN\"\n",
        "        else:\n",
        "            col_type = \"STRING\"\n",
        "        schema.append(bigquery.SchemaField(col, col_type, mode=\"NULLABLE\"))\n",
        "\n",
        "  # Convert DataFrame to BigQuery table\n",
        "    table_ref = bigquery.TableReference.from_string(f\"{project_id}.{dataset_id}.{table_id}\")\n",
        "    table = bigquery.Table(table_ref, schema= schema)\n",
        "\n",
        "  # Stream the DataFrame data to the BigQuery tabl\n",
        "    job_config = bigquery.LoadJobConfig(write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE, create_disposition=\"CREATE_IF_NEEDED\")\n",
        "    client.load_table_from_dataframe(agents, table, job_config=job_config).result()\n",
        "\n",
        "    print(\"Data streamed to BigQuery successfully.\")\n",
        "\n",
        "def main():\n",
        "    # Authenticate with Google Colab\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    agents_table_id = 'agents_data'\n",
        "    load_agents_dataframe_to_bigquery(agents, project_id, dataset_id, agents_table_id)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COr3SpHdmKt0",
        "outputId": "ed483a8d-5af5-4bc0-bd93-1667ac5d6d8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter username: d.momodu\n",
            "Please enter your password: ··········\n",
            "API token obtained: b464ef0bc14b14f9e070d9b5831087a55caaa7c2\n",
            "Data streamed to BigQuery successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRANSACTION DATA\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import time\n",
        "import getpass\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from google.cloud.bigquery.job import WriteDisposition\n",
        "\n",
        "\n",
        "# Define your site IDs\n",
        "aninigi_id = \"bce9a7b0-57f1-4f34-a34e-159870aaecd5\"\n",
        "lafiya_kpada_id = \"75503047-1a72-4582-bef3-1ce3f784a77d\"\n",
        "maijaki_id = \"f59da0c8-c6fe-4041-a8f6-545572b5d7be\"\n",
        "mbiabet_id = \"08f41ab4-afa0-4a2a-a5b9-3658afb93fdc\"\n",
        "\n",
        "# List of site IDs\n",
        "site_ids = [aninigi_id, lafiya_kpada_id, maijaki_id, mbiabet_id]\n",
        "\n",
        "# Headers with placeholders\n",
        "headers = {\n",
        "    'X-API-KEY': 'ng5JU0UhoQalLYg1tNnDXFRq_4T5-F92JPqvn9f819Y',\n",
        "    'X-API-SECRET': 'mZbvDVjQ46x1Z*4L1KSYuOMce16ItHj^',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "def get_data(site_id):\n",
        "    transaction_url = \"https://www.sparkmeter.cloud/api/v0/organizations/29bba916-61b9-4f84-9a51-44478e184a80/data/historical\"\n",
        "    data = {\n",
        "        \"per_page\": 100,\n",
        "        \"filters\": {\n",
        "            \"sites\": [site_id],\n",
        "            \"entity_types\": [\"transactions\"]\n",
        "        }\n",
        "    }\n",
        "    all_data = []\n",
        "    while True:\n",
        "        response = requests.post(transaction_url, json=data, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            response_data = response.json()\n",
        "            all_data.extend(response_data[\"results\"])\n",
        "\n",
        "            if response_data.get('cursor'):\n",
        "                data = {\"cursor\": response_data['cursor']}\n",
        "                time.sleep(1.1)  # Added sleep here to respect rate limit\n",
        "            else:\n",
        "                break\n",
        "        elif response.status_code == 429:  # Rate limit exceeded\n",
        "            time.sleep(1.1)  # Added sleep here to respect rate limit\n",
        "        else:\n",
        "            print(f\"Error: {response.status_code} - {response.text}\")\n",
        "            break\n",
        "\n",
        "    return [(site_id, flatten_dict(record)) for record in all_data]\n",
        "\n",
        "# Flatten the nested dictionary\n",
        "def flatten_dict(d, parent_key='', sep='_'):\n",
        "    items = []\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "        if isinstance(v, dict):\n",
        "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
        "        else:\n",
        "            items.append((new_key, v))\n",
        "    return dict(items)\n",
        "\n",
        "all_transactions = []\n",
        "\n",
        "# Parallelizing the API calls\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future_to_site = {executor.submit(get_data, site_id): site_id for site_id in site_ids}\n",
        "    for future in as_completed(future_to_site):\n",
        "        site_id = future_to_site[future]\n",
        "        try:\n",
        "            data = future.result()\n",
        "        except Exception as exc:\n",
        "            print(f\"{site_id} generated an exception: {exc}\")\n",
        "        else:\n",
        "            all_transactions.extend(data)\n",
        "\n",
        "# Convert to DataFrame\n",
        "all_trans_df = pd.DataFrame.from_records([record for _, record in all_transactions])\n",
        "\n",
        "all_trans_df['to_address_coords_lon'].fillna(0.0, inplace = True)\n",
        "all_trans_df['to_address_coords_lat'].fillna(0.0, inplace = True)\n",
        "\n",
        "\n",
        "all_trans_df.rename(columns = {'from_name':'agent_name', 'from_wallet_type':'wallet_type', 'from_id':'agent_id',\n",
        "                               'state':'transaction_status','site':'site_id', 'to_serial':'meter_number',\n",
        "                               'to_wallet_type':'wallet_type', 'to_tariff_name':'tariff_name', 'to_tariff_id':'tariff_id',\n",
        "                               'to_type':'type', 'to_customer_name':'customer_name', 'to_customer_phone_number':'phone_number',\n",
        "                               'to_customer_id':'customer_id', 'created':'transaction_date'}, inplace = True)\n",
        "\n",
        "all_trans_df = all_trans_df[all_trans_df['transaction_status'] == 'processed']\n",
        "\n",
        "all_trans_df.loc[all_trans_df['site_id'] == \"bce9a7b0-57f1-4f34-a34e-159870aaecd5\", 'site_name'] = 'Aninigi'\n",
        "all_trans_df.loc[all_trans_df['site_id'] == \"75503047-1a72-4582-bef3-1ce3f784a77d\", 'site_name'] = 'Lafiya_kpada'\n",
        "all_trans_df.loc[all_trans_df['site_id'] == \"f59da0c8-c6fe-4041-a8f6-545572b5d7be\", 'site_name'] = 'Maijaki'\n",
        "all_trans_df.loc[~all_trans_df['site_id'].isin([\"bce9a7b0-57f1-4f34-a34e-159870aaecd5\", \"75503047-1a72-4582-bef3-1ce3f784a77d\", \"f59da0c8-c6fe-4041-a8f6-545572b5d7be\"]), 'site_name'] = 'Mbiabet'\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "all_trans_df = all_trans_df[['site_name', 'origin', 'acct_type', 'source', 'amount','transaction_date', 'customer_name',\n",
        "                              'phone_number','meter_number', 'tariff_name', 'agent_name', 'agent_id', 'id', 'tariff_id',\n",
        "                              'site_id', 'customer_id', 'reference_id']]\n",
        "\n",
        "\n",
        "#STEAMACO DATA\n",
        "def get_api_token(username, password):\n",
        "    token_endpoint = \"https://api.steama.co/get-token/\"\n",
        "    payload = {\"username\": username, \"password\": password}\n",
        "    response = requests.post(token_endpoint, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"token\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Error obtaining API token: {response.status_code} - {response.text}\")\n",
        "\n",
        "def get_transaction_data(api_token, base_url=\"https://api.steama.co\", page_size=100):\n",
        "    transactions_endpoint = f\"{base_url}/transactions/\"\n",
        "    headers = {'Authorization': f\"Token {api_token}\"}\n",
        "    all_data = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        url = f\"{transactions_endpoint}?page={page}&page_size={page_size}\"\n",
        "        response = requests.get(url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            all_data.extend(data[\"results\"])\n",
        "\n",
        "            if data[\"next\"]:\n",
        "                page += 1\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            print(f\"Error: {response.status_code} - {response.text}\")\n",
        "            break\n",
        "\n",
        "    transactions = pd.DataFrame.from_records(all_data)\n",
        "    return transactions\n",
        "\n",
        "def main():\n",
        "    username = input(\"Please enter username: \")\n",
        "    password = getpass.getpass(\"Please enter your password: \")\n",
        "\n",
        "    try:\n",
        "        api_token = get_api_token(username, password)\n",
        "        print(f\"API token obtained: {api_token}\")\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        exit(1)\n",
        "\n",
        "    transactions = get_transaction_data(api_token)\n",
        "    transactions = transactions.applymap(lambda x: str(x) if isinstance(x, list) else x)\n",
        "\n",
        "    transactions['customer_name'] = transactions['customer_first_name'] + ' ' + transactions['customer_last_name']\n",
        "    transactions['agent_name'] = transactions['agent_first_name'] + ' ' + transactions['agent_last_name']\n",
        "    transactions = transactions[transactions['category'] == 'SUB']\n",
        "    transactions.rename(columns = {'timestamp':'transaction_date','raw_message':'reference_id',\n",
        "                                   'customer_telephone':'phone_number'}, inplace = True)\n",
        "    transactions['origin'] = ' '\n",
        "    transactions['acct_type'] = ' '\n",
        "    transactions['source'] = ' '\n",
        "    transactions['meter_number'] = ' '\n",
        "    transactions['tariff_name'] = ' '\n",
        "    transactions['tariff_id'] = ' '\n",
        "\n",
        "    transactions = transactions[['site_name', 'origin', 'acct_type', 'source', 'amount','transaction_date', 'customer_name',\n",
        "                                 'phone_number','meter_number', 'tariff_name','agent_name', 'agent_id', 'id','tariff_id',\n",
        "                                 'site_id', 'customer_id', 'reference_id']]\n",
        "\n",
        "    return transactions\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    trans_df = main()\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "trans_frame = [all_trans_df,trans_df]\n",
        "transaction_data = pd.concat(trans_frame)\n",
        "transaction_data = transaction_data.astype(str)\n",
        "\n",
        "project_id = \"minigrid-db-395810\"\n",
        "dataset_id = \"Transactions\"\n",
        "\n",
        "auth.authenticate_user()\n",
        "client =bigquery.Client(project=project_id)\n",
        "\n",
        "def func2(df):\n",
        "  schema = []\n",
        "  for col in df.columns:\n",
        "    if df[col].dtype.name.lower() == \"int64\":\n",
        "      col_type = \"INTEGER\"\n",
        "    elif df[col].dtype.name.lower() == \"float64\":\n",
        "      col_type = \"FLOAT\"\n",
        "    elif df[col].dtype.name.lower() == \"bool\":\n",
        "      col_type = \"BOOLEAN\"\n",
        "    else:\n",
        "      col_type = \"STRING\"\n",
        "  schema.append(bigquery.SchemaField(col, col_type, mode=\"NULLABLE\"))\n",
        "  return schema\n",
        "\n",
        "transaction_table_id = \"transaction_data\"\n",
        "transaction_table_ref = bigquery.TableReference.from_string(f\"{project_id}.{dataset_id}.{transaction_table_id}\")\n",
        "transaction_table = bigquery.Table(transaction_table_ref, schema= func2(transaction_data))\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE, create_disposition=\"CREATE_IF_NEEDED\")\n",
        "client.load_table_from_dataframe(transaction_data, transaction_table, job_config=job_config).result()\n",
        "\n",
        "print(\"Data streamed to BigQuery successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmhmrh_9msxZ",
        "outputId": "b2e9940d-0a7d-4fe3-8beb-4a3382f32ab1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-90bdcb3cd5c3>:99: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  all_trans_df.loc[all_trans_df['site_id'] == \"bce9a7b0-57f1-4f34-a34e-159870aaecd5\", 'site_name'] = 'Aninigi'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter username: d.momodu\n",
            "Please enter your password: ··········\n",
            "API token obtained: b464ef0bc14b14f9e070d9b5831087a55caaa7c2\n",
            "Data streamed to BigQuery successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pNX8NXcElviZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}